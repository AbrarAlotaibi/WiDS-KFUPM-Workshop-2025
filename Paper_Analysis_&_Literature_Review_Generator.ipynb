{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFHQKaT2iK9A6dupW9C+vb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbrarAlotaibi/WiDS-KFUPM-Workshop-2025/blob/main/Paper_Analysis_%26_Literature_Review_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paper Analysis & Literature Review Generator\n",
        "\n",
        "By: Abrar Aloyaibi\n",
        "\n",
        "This notebook allows you to:\n",
        "1. Load filtered papers from a CSV file (from our previous filtering system)\n",
        "2. Generate a comprehensive literature review\n",
        "3. Create a comparison table of the papers\n",
        "4. Export results to CSV and LaTeX (for Overleaf)\n"
      ],
      "metadata": {
        "id": "GdlyPlFXy90n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RJAx72Ty2xy"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "# Uncomment and run if needed\n",
        "#!pip install openai pandas matplotlib tqdm pylatex PyPDF2\n",
        "\n",
        "import pandas as pd\n",
        "import openai\n",
        "import json\n",
        "import time\n",
        "import re\n",
        "import numpy as np\n",
        "from IPython.display import display, HTML, Markdown\n",
        "from datetime import datetime\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import PyPDF2\n",
        "import io\n",
        "import requests\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set your OpenAI API key\n",
        "OPENAI_API_KEY = \"your-openai-api-key-here\"\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "# Verify API key is set (this doesn't check if it's valid, just that it's set)\n",
        "if openai.api_key and openai.api_key != \"your-openai-api-key-here\":\n",
        "    print(\"✅ API key configured.\")\n",
        "else:\n",
        "    print(\"⚠️ Please replace the placeholder with your actual OpenAI API key.\")\n",
        "\n",
        "print(\"Libraries imported and API key configured.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load papers from CSV"
      ],
      "metadata": {
        "id": "WnngC8MV1f4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_papers_from_csv(csv_file_path):\n",
        "    \"\"\"\n",
        "    Load papers from a CSV file and prepare them for analysis\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    csv_file_path : str\n",
        "        Path to the CSV file containing paper data\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    DataFrame\n",
        "        Pandas DataFrame containing the paper data\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load the CSV file\n",
        "        print(f\"Loading papers from {csv_file_path}...\")\n",
        "        df = pd.read_csv(csv_file_path)\n",
        "\n",
        "        # Check required columns\n",
        "        required_columns = ['title', 'authors', 'summary', 'link', 'relevanceScore']\n",
        "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "\n",
        "        if missing_columns:\n",
        "            print(f\"Warning: Missing required columns: {', '.join(missing_columns)}\")\n",
        "            return None\n",
        "\n",
        "        # Convert string representations of lists back to actual lists\n",
        "        if 'authors' in df.columns and isinstance(df['authors'].iloc[0], str):\n",
        "            df['authors'] = df['authors'].apply(lambda x: eval(x) if isinstance(x, str) and '[' in x else x)\n",
        "\n",
        "        if 'keyMatchingConcepts' in df.columns and isinstance(df['keyMatchingConcepts'].iloc[0], str):\n",
        "            df['keyMatchingConcepts'] = df['keyMatchingConcepts'].apply(lambda x: eval(x) if isinstance(x, str) and '[' in x else x)\n",
        "\n",
        "        # Display a summary of the loaded papers\n",
        "        print(f\"Successfully loaded {len(df)} papers.\")\n",
        "        print(f\"Relevance score range: {df['relevanceScore'].min()} - {df['relevanceScore'].max()}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading papers: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example usage:\n",
        "papers_df = load_papers_from_csv('arxiv_filtered_papers.csv')\n",
        "if papers_df is not None:\n",
        "     display(papers_df.head(3))"
      ],
      "metadata": {
        "id": "B0aj7bohz8Qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download and Extract Text from PDFs"
      ],
      "metadata": {
        "id": "npo5v56_5gcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_extract_paper_text(paper_link):\n",
        "    \"\"\"\n",
        "    Download a paper PDF from arXiv and extract its text content\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    paper_link : str\n",
        "        arXiv link or ID for the paper\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    str\n",
        "        Extracted text content from the PDF\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Extract arXiv ID from the link\n",
        "        arxiv_id = paper_link.split('/')[-1]\n",
        "        if 'abs' in arxiv_id:\n",
        "            arxiv_id = arxiv_id.replace('abs/', '')\n",
        "\n",
        "        print(f\"Downloading PDF for arXiv ID: {arxiv_id}\")\n",
        "\n",
        "        # Construct PDF URL\n",
        "        pdf_url = f\"https://arxiv.org/pdf/{arxiv_id}.pdf\"\n",
        "\n",
        "        # Download the PDF\n",
        "        response = requests.get(pdf_url)\n",
        "        if response.status_code != 200:\n",
        "            print(f\"Failed to download PDF: {response.status_code}\")\n",
        "            return None\n",
        "\n",
        "        # Parse the PDF content\n",
        "        try:\n",
        "            pdf_content = io.BytesIO(response.content)\n",
        "            pdf_reader = PyPDF2.PdfReader(pdf_content)\n",
        "\n",
        "            # Extract text from each page\n",
        "            text = \"\"\n",
        "            for page_num in range(len(pdf_reader.pages)):\n",
        "                page = pdf_reader.pages[page_num]\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "\n",
        "            print(f\"Successfully extracted {len(text)} characters from PDF\")\n",
        "\n",
        "            # Basic cleaning\n",
        "            text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with single space\n",
        "\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting text from PDF: {e}\")\n",
        "            return None\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"PyPDF2 module not installed. Installing now...\")\n",
        "        try:\n",
        "\n",
        "            # Retry extraction after installation\n",
        "            return download_and_extract_paper_text(paper_link)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to install or use PyPDF2: {e}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing paper: {e}\")\n",
        "        return None\n",
        "\n",
        "def enhance_papers_with_full_text(papers_df, max_papers=None):\n",
        "    \"\"\"\n",
        "    Download and add full text content to papers\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    papers_df : DataFrame\n",
        "        DataFrame containing papers\n",
        "    max_papers : int, optional\n",
        "        Maximum number of papers to process\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    DataFrame\n",
        "        Papers DataFrame with added full_text column\n",
        "    \"\"\"\n",
        "    if papers_df is None or len(papers_df) == 0:\n",
        "        print(\"No papers available.\")\n",
        "        return papers_df\n",
        "\n",
        "    # Sort by relevance and limit number of papers if specified\n",
        "    if max_papers is not None and max_papers < len(papers_df):\n",
        "        papers_to_process = papers_df.sort_values('relevanceScore', ascending=False).head(max_papers)\n",
        "    else:\n",
        "        papers_to_process = papers_df\n",
        "\n",
        "    # Add a new column for full text\n",
        "    papers_to_process['full_text'] = None\n",
        "\n",
        "    print(f\"Downloading and extracting text from {len(papers_to_process)} papers...\")\n",
        "\n",
        "    # Process each paper\n",
        "    for idx, paper in tqdm(papers_to_process.iterrows(), total=len(papers_to_process)):\n",
        "        # Download and extract text\n",
        "        full_text = download_and_extract_paper_text(paper['link'])\n",
        "\n",
        "        # Update the DataFrame\n",
        "        if full_text:\n",
        "            papers_df.at[idx, 'full_text'] = full_text\n",
        "        else:\n",
        "            # If extraction failed, use summary instead\n",
        "            papers_df.at[idx, 'full_text'] = paper['summary']\n",
        "            print(f\"Using abstract as fallback for paper: {paper['title']}\")\n",
        "\n",
        "    # Count papers with full text\n",
        "    full_text_count = papers_df['full_text'].notnull().sum()\n",
        "    print(f\"Successfully added full text to {full_text_count} papers.\")\n",
        "\n",
        "    return papers_df\n",
        "\n",
        "# Example usage:\n",
        "enhanced_df = enhance_papers_with_full_text(papers_df, max_papers=5)\n",
        "print(f\"First paper text length: {len(enhanced_df['full_text'].iloc[0])} characters\")"
      ],
      "metadata": {
        "id": "iRvkLUDo5hay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Literature Review Generation"
      ],
      "metadata": {
        "id": "WgVXcC5t1nrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_literature_review(papers_df, research_interest, min_relevance=70, max_papers=10):\n",
        "    \"\"\"\n",
        "    Generate a comprehensive literature review from selected papers\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    papers_df : DataFrame\n",
        "        DataFrame containing the papers\n",
        "    research_interest : str\n",
        "        Research interest that the review should focus on\n",
        "    min_relevance : int\n",
        "        Minimum relevance score to include papers (0-100)\n",
        "    max_papers : int\n",
        "        Maximum number of papers to include in the review\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    str\n",
        "        Generated literature review text\n",
        "    list\n",
        "        List of papers included in the review\n",
        "    \"\"\"\n",
        "    if papers_df is None or len(papers_df) == 0:\n",
        "        print(\"No papers available for review generation.\")\n",
        "        return None, []\n",
        "\n",
        "    # Filter papers by relevance score and take top N\n",
        "    relevant_papers = papers_df[papers_df['relevanceScore'] >= min_relevance]\n",
        "    relevant_papers = relevant_papers.sort_values('relevanceScore', ascending=False).head(max_papers)\n",
        "\n",
        "    if len(relevant_papers) == 0:\n",
        "        print(f\"No papers with relevance score >= {min_relevance} found.\")\n",
        "        return None, []\n",
        "\n",
        "    print(f\"Generating literature review based on {len(relevant_papers)} papers...\")\n",
        "\n",
        "    # First, ensure we have full text for the papers if available\n",
        "    if 'full_text' not in relevant_papers.columns:\n",
        "        print(\"Full text not found. Downloading papers...\")\n",
        "        relevant_papers = enhance_papers_with_full_text(relevant_papers, max_papers=max_papers)\n",
        "\n",
        "    # Prepare paper information for OpenAI\n",
        "    papers_info = []\n",
        "    for idx, paper in relevant_papers.iterrows():\n",
        "        # Handle different author formats\n",
        "        if isinstance(paper['authors'], list):\n",
        "            authors_str = ', '.join(paper['authors'])\n",
        "        elif isinstance(paper['authors'], str):\n",
        "            # If it's already a string but not properly converted\n",
        "            if paper['authors'].startswith('[') and paper['authors'].endswith(']'):\n",
        "                authors_str = ', '.join(eval(paper['authors']))\n",
        "            else:\n",
        "                authors_str = paper['authors']\n",
        "        else:\n",
        "            authors_str = \"Unknown Authors\"\n",
        "\n",
        "        # Get the paper text content (full text if available, summary as fallback)\n",
        "        if 'full_text' in paper and paper['full_text'] is not None:\n",
        "            content = paper['full_text']\n",
        "            # Truncate if too long for API context window\n",
        "            if len(content) > 15000:\n",
        "                content = content[:15000] + \"... [truncated]\"\n",
        "        else:\n",
        "            content = paper['summary']\n",
        "\n",
        "        # Create a structured representation of each paper\n",
        "        paper_info = {\n",
        "            'title': paper['title'],\n",
        "            'authors': authors_str,\n",
        "            'content': content,\n",
        "            'relevance': paper['relevanceScore'],\n",
        "            'link': paper['link']\n",
        "        }\n",
        "        papers_info.append(paper_info)\n",
        "\n",
        "    # Create a prompt for OpenAI to generate the literature review\n",
        "    papers_text = \"\"\n",
        "    for i, paper in enumerate(papers_info, 1):\n",
        "        papers_text += f\"Paper {i}:\\n\"\n",
        "        papers_text += f\"Title: {paper['title']}\\n\"\n",
        "        papers_text += f\"Authors: {paper['authors']}\\n\"\n",
        "        papers_text += f\"Content: {paper['content'][:800]}... [content truncated for prompt]\\n\"\n",
        "        papers_text += f\"Relevance Score: {paper['relevance']}\\n\\n\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "I need you to create a comprehensive literature review based on the following papers,\n",
        "focusing on the research interest: \"{research_interest}\".\n",
        "\n",
        "{papers_text}\n",
        "\n",
        "Please follow this structure for the literature review:\n",
        "1. Introduction: Provide an overview of the research area and its importance.\n",
        "2. Main Body: Analyze and synthesize the key findings, methodologies, and contributions of each paper,\n",
        "   organizing by themes rather than discussing papers individually.\n",
        "3. Gaps and Future Directions: Identify gaps in the literature and suggest future research directions.\n",
        "4. Conclusion: Summarize the main insights from this literature review.\n",
        "\n",
        "The literature review should be well-structured, scholarly, and about 1000-1500 words.\n",
        "\n",
        "Format your response as:\n",
        "<literature-review>\n",
        "[The complete literature review text here]\n",
        "</literature-review>\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Call OpenAI API to generate the literature review\n",
        "        response = openai.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a research assistant specialized in creating comprehensive literature reviews from scientific papers. You excel at synthesizing information across multiple papers and identifying connections, themes, and gaps in the literature.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.3,  # Lower temperature for more scholarly output\n",
        "            max_tokens=4000   # Allow enough tokens for a comprehensive review\n",
        "        )\n",
        "\n",
        "        # Extract the literature review from the response\n",
        "        review_text = response.choices[0].message.content\n",
        "\n",
        "        # Try to extract content between <literature-review> tags if present\n",
        "        if \"<literature-review>\" in review_text and \"</literature-review>\" in review_text:\n",
        "            review_text = re.search(r'<literature-review>(.*?)</literature-review>', review_text, re.DOTALL).group(1).strip()\n",
        "\n",
        "        print(\"Literature review generated successfully!\")\n",
        "        return review_text, papers_info\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating literature review: {e}\")\n",
        "        return None, papers_info\n",
        "\n",
        "# Example usage:\n",
        "# research_interest = \"Applications of reinforcement learning in robotic control systems with sparse rewards\"\n",
        "# review_text, included_papers = generate_literature_review(papers_df, research_interest, min_relevance=70, max_papers=8)\n",
        "# if review_text:\n",
        "#     display(Markdown(\"## Generated Literature Review\"))\n",
        "#     display(Markdown(review_text))"
      ],
      "metadata": {
        "id": "pmE7qbTb1juc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Comparison Table"
      ],
      "metadata": {
        "id": "lgONMiIS2ONW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_comparison_table(papers_df, min_relevance=70, max_papers=10):\n",
        "    \"\"\"\n",
        "    Create a structured comparison table of papers\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    papers_df : DataFrame\n",
        "        DataFrame containing the papers\n",
        "    min_relevance : int\n",
        "        Minimum relevance score to include papers (0-100)\n",
        "    max_papers : int\n",
        "        Maximum number of papers to include in the table\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    DataFrame\n",
        "        Comparison table as a DataFrame\n",
        "    list\n",
        "        List of papers included in the table\n",
        "    \"\"\"\n",
        "    if papers_df is None or len(papers_df) == 0:\n",
        "        print(\"No papers available for table creation.\")\n",
        "        return None, []\n",
        "\n",
        "    # Filter papers by relevance score and take top N\n",
        "    relevant_papers = papers_df[papers_df['relevanceScore'] >= min_relevance]\n",
        "    relevant_papers = relevant_papers.sort_values('relevanceScore', ascending=False).head(max_papers)\n",
        "\n",
        "    if len(relevant_papers) == 0:\n",
        "        print(f\"No papers with relevance score >= {min_relevance} found.\")\n",
        "        return None, []\n",
        "\n",
        "    print(f\"Creating comparison table for {len(relevant_papers)} papers...\")\n",
        "\n",
        "    # First, ensure we have full text for the papers if available\n",
        "    if 'full_text' not in relevant_papers.columns:\n",
        "        print(\"Full text not found. Downloading papers...\")\n",
        "        relevant_papers = enhance_papers_with_full_text(relevant_papers, max_papers=max_papers)\n",
        "\n",
        "    # Prepare papers for analysis\n",
        "    papers_info = []\n",
        "    for idx, paper in relevant_papers.iterrows():\n",
        "        # Handle different author formats\n",
        "        if isinstance(paper['authors'], list):\n",
        "            authors_str = ', '.join(paper['authors'])\n",
        "        elif isinstance(paper['authors'], str):\n",
        "            if paper['authors'].startswith('[') and paper['authors'].endswith(']'):\n",
        "                authors_str = ', '.join(eval(paper['authors']))\n",
        "            else:\n",
        "                authors_str = paper['authors']\n",
        "        else:\n",
        "            authors_str = \"Unknown Authors\"\n",
        "\n",
        "        # Get the paper text content (full text if available, summary as fallback)\n",
        "        if 'full_text' in paper and paper['full_text'] is not None:\n",
        "            content = paper['full_text']\n",
        "            # Truncate if too long for API context window\n",
        "            if len(content) > 15000:\n",
        "                content = content[:15000] + \"... [truncated]\"\n",
        "        else:\n",
        "            content = paper['summary']\n",
        "\n",
        "        # Create a structured representation of each paper\n",
        "        paper_info = {\n",
        "            'title': paper['title'],\n",
        "            'authors': authors_str,\n",
        "            'content': content,\n",
        "            'relevance': paper['relevanceScore'],\n",
        "            'link': paper['link']\n",
        "        }\n",
        "        papers_info.append(paper_info)\n",
        "\n",
        "    # Use OpenAI to extract key aspects of each paper\n",
        "    enhanced_papers = []\n",
        "\n",
        "    print(\"Analyzing papers for comparison table...\")\n",
        "    for i, paper in enumerate(tqdm(papers_info)):\n",
        "        try:\n",
        "            # Create a prompt for OpenAI to extract key information\n",
        "            prompt = f\"\"\"\n",
        "Analyze the following scientific paper and extract key information in a structured format.\n",
        "\n",
        "Title: {paper['title']}\n",
        "Authors: {paper['authors']}\n",
        "Content: {paper['content'][:3000]}... [content truncated for prompt]\n",
        "\n",
        "Extract the following information in JSON format:\n",
        "1. Main research question or objective\n",
        "2. Methodology used (techniques, approaches, models)\n",
        "3. Key findings or results\n",
        "4. Limitations mentioned\n",
        "5. Future work suggested\n",
        "6. Year of publication (if available in the content, otherwise estimate based on context)\n",
        "\n",
        "Format your response as a JSON object with the following keys:\n",
        "{{\n",
        "  \"research_question\": \"The main research question or objective\",\n",
        "  \"methodology\": \"The methodology, techniques, approaches used\",\n",
        "  \"key_findings\": \"The main findings or results\",\n",
        "  \"limitations\": \"Limitations of the study\",\n",
        "  \"future_work\": \"Suggested future work\",\n",
        "  \"year\": \"Publication year (or estimate)\",\n",
        "  \"key_themes\": [\"theme1\", \"theme2\", \"theme3\"]\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "            # Call OpenAI API to analyze the paper\n",
        "            response = openai.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",  # Use a faster model for individual paper analysis\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a research assistant specialized in analyzing scientific papers and extracting key information. Be precise and concise.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.2,\n",
        "                response_format={\"type\": \"json_object\"}\n",
        "            )\n",
        "\n",
        "            # Parse the JSON response\n",
        "            analysis = json.loads(response.choices[0].message.content)\n",
        "\n",
        "            # Add the analysis to the paper info\n",
        "            enhanced_paper = paper.copy()\n",
        "            enhanced_paper.update(analysis)\n",
        "            enhanced_papers.append(enhanced_paper)\n",
        "\n",
        "            # Add a small delay to avoid rate limits\n",
        "            time.sleep(0.5)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error analyzing paper {i+1}: {e}\")\n",
        "            # Add the original paper without enhanced analysis\n",
        "            enhanced_papers.append(paper)\n",
        "\n",
        "    # Create a comparison table as a DataFrame\n",
        "    table_data = []\n",
        "    for paper in enhanced_papers:\n",
        "        # Extract key information for the table\n",
        "        row = {\n",
        "            'Title': paper['title'],\n",
        "            'Authors': paper['authors'],\n",
        "            'Relevance': paper['relevance'],\n",
        "            'Research Question': paper.get('research_question', 'N/A'),\n",
        "            'Methodology': paper.get('methodology', 'N/A'),\n",
        "            'Key Findings': paper.get('key_findings', 'N/A'),\n",
        "            'Limitations': paper.get('limitations', 'N/A'),\n",
        "            'Future Work': paper.get('future_work', 'N/A'),\n",
        "            'Year': paper.get('year', 'N/A'),\n",
        "            'Link': paper['link']\n",
        "        }\n",
        "        table_data.append(row)\n",
        "\n",
        "    # Create a DataFrame from the table data\n",
        "    comparison_table = pd.DataFrame(table_data)\n",
        "\n",
        "    print(\"Comparison table created successfully!\")\n",
        "    return comparison_table, enhanced_papers\n",
        "\n",
        "# Example usage:\n",
        "# comparison_df, enhanced_papers = create_comparison_table(papers_df, min_relevance=70, max_papers=8)\n",
        "# if comparison_df is not None:\n",
        "#     display(comparison_df)"
      ],
      "metadata": {
        "id": "UdXY2CNV2apD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export for CSV"
      ],
      "metadata": {
        "id": "aOxmcNpS2jJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def export_to_csv(data, filename, data_type=\"comparison\"):\n",
        "    \"\"\"\n",
        "    Export data to a CSV file\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    data : DataFrame or str\n",
        "        Data to export (DataFrame for comparison table, str for literature review)\n",
        "    filename : str\n",
        "        Name for the output file\n",
        "    data_type : str\n",
        "        Type of data being exported ('comparison' or 'literature')\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    str\n",
        "        Path to the exported file\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if data_type == \"comparison\" and isinstance(data, pd.DataFrame):\n",
        "            # Export comparison table\n",
        "            output_path = f\"{filename}.csv\"\n",
        "            data.to_csv(output_path, index=False)\n",
        "            print(f\"Comparison table exported to {output_path}\")\n",
        "            return output_path\n",
        "\n",
        "        elif data_type == \"literature\" and isinstance(data, str):\n",
        "            # Export literature review as CSV\n",
        "            # Create a DataFrame with the review text\n",
        "            df = pd.DataFrame({\n",
        "                'section': ['Literature Review'],\n",
        "                'content': [data]\n",
        "            })\n",
        "            output_path = f\"{filename}.csv\"\n",
        "            df.to_csv(output_path, index=False)\n",
        "            print(f\"Literature review exported to {output_path}\")\n",
        "            return output_path\n",
        "\n",
        "        else:\n",
        "            print(f\"Invalid data type or format for CSV export: {data_type}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error exporting to CSV: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example usage:\n",
        "# if comparison_df is not None:\n",
        "#     export_to_csv(comparison_df, \"paper_comparison_table\", \"comparison\")\n",
        "# if review_text:\n",
        "#     export_to_csv(review_text, \"literature_review\", \"literature\")"
      ],
      "metadata": {
        "id": "tsYHQpS32m15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export to LaTeX (for Overleaf)"
      ],
      "metadata": {
        "id": "ZcIWZY352tcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def export_to_latex(data, filename, data_type=\"comparison\", research_interest=\"\"):\n",
        "    \"\"\"\n",
        "    Export data to LaTeX format for use in Overleaf\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    data : DataFrame or str\n",
        "        Data to export (DataFrame for comparison table, str for literature review)\n",
        "    filename : str\n",
        "        Name for the output file\n",
        "    data_type : str\n",
        "        Type of data being exported ('comparison' or 'literature')\n",
        "    research_interest : str\n",
        "        The research interest for the title (optional)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    str\n",
        "        Path to the exported file\n",
        "    \"\"\"\n",
        "    try:\n",
        "        output_path = f\"{filename}.txt\"\n",
        "\n",
        "        if data_type == \"comparison\" and isinstance(data, pd.DataFrame):\n",
        "            # Create LaTeX for comparison table\n",
        "            latex_content = \"% LaTeX Comparison Table for Overleaf\\n\"\n",
        "            latex_content += \"% Generated on \" + datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \"\\n\\n\"\n",
        "\n",
        "            # Add document class and packages\n",
        "            latex_content += \"\\\\documentclass{article}\\n\"\n",
        "            latex_content += \"\\\\usepackage[utf8]{inputenc}\\n\"\n",
        "            latex_content += \"\\\\usepackage{booktabs}\\n\"\n",
        "            latex_content += \"\\\\usepackage{longtable}\\n\"\n",
        "            latex_content += \"\\\\usepackage{array}\\n\"\n",
        "            latex_content += \"\\\\usepackage{multirow}\\n\"\n",
        "            latex_content += \"\\\\usepackage{pdflscape}\\n\"\n",
        "            latex_content += \"\\\\usepackage{tabu}\\n\"\n",
        "            latex_content += \"\\\\usepackage{hyperref}\\n\\n\"\n",
        "\n",
        "            # Begin document\n",
        "            latex_content += \"\\\\begin{document}\\n\\n\"\n",
        "\n",
        "            # Add title\n",
        "            if research_interest:\n",
        "                latex_content += f\"\\\\title{{Comparison of Papers on {research_interest}}}\\n\"\n",
        "            else:\n",
        "                latex_content += \"\\\\title{Comparison of Scientific Papers}\\n\"\n",
        "            latex_content += \"\\\\author{Generated with AI Literature Review Tool}\\n\"\n",
        "            latex_content += \"\\\\date{\\\\today}\\n\"\n",
        "            latex_content += \"\\\\maketitle\\n\\n\"\n",
        "\n",
        "            # Begin landscape for wide table\n",
        "            latex_content += \"\\\\begin{landscape}\\n\"\n",
        "\n",
        "            # Select columns to include in the table\n",
        "            columns = ['Title', 'Authors', 'Year', 'Research Question', 'Methodology', 'Key Findings']\n",
        "\n",
        "            # Create the table\n",
        "            latex_content += \"\\\\begin{longtabu} to \\\\linewidth {|p{3cm}|p{3cm}|p{1cm}|p{4cm}|p{4cm}|p{4cm}|}\\n\"\n",
        "            latex_content += \"\\\\caption{Comparison of Scientific Papers} \\\\\\\\\\n\"\n",
        "\n",
        "            # Add table header\n",
        "            latex_content += \"\\\\hline\\n\"\n",
        "            latex_content += \" & \".join([f\"\\\\textbf{{{col}}}\" for col in columns]) + \" \\\\\\\\\\n\"\n",
        "            latex_content += \"\\\\hline\\n\"\n",
        "            latex_content += \"\\\\endhead\\n\\n\"\n",
        "\n",
        "            # Add table rows\n",
        "            for _, row in data[columns].iterrows():\n",
        "                latex_row = []\n",
        "                for col in columns:\n",
        "                    # Clean the content for LaTeX\n",
        "                    content = str(row[col]).replace('_', '\\\\_').replace('%', '\\\\%').replace('&', '\\\\&')\n",
        "                    latex_row.append(content)\n",
        "\n",
        "                latex_content += \" & \".join(latex_row) + \" \\\\\\\\\\n\"\n",
        "                latex_content += \"\\\\hline\\n\"\n",
        "\n",
        "            # End table\n",
        "            latex_content += \"\\\\end{longtabu}\\n\"\n",
        "            latex_content += \"\\\\end{landscape}\\n\\n\"\n",
        "\n",
        "            # End document\n",
        "            latex_content += \"\\\\end{document}\"\n",
        "\n",
        "        elif data_type == \"literature\" and isinstance(data, str):\n",
        "            # Create LaTeX for literature review\n",
        "            latex_content = \"% LaTeX Literature Review for Overleaf\\n\"\n",
        "            latex_content += \"% Generated on \" + datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \"\\n\\n\"\n",
        "\n",
        "            # Add document class and packages\n",
        "            latex_content += \"\\\\documentclass{article}\\n\"\n",
        "            latex_content += \"\\\\usepackage[utf8]{inputenc}\\n\"\n",
        "            latex_content += \"\\\\usepackage{natbib}\\n\"\n",
        "            latex_content += \"\\\\usepackage{hyperref}\\n\"\n",
        "            latex_content += \"\\\\usepackage{booktabs}\\n\\n\"\n",
        "\n",
        "            # Begin document\n",
        "            latex_content += \"\\\\begin{document}\\n\\n\"\n",
        "\n",
        "            # Add title\n",
        "            if research_interest:\n",
        "                latex_content += f\"\\\\title{{Literature Review: {research_interest}}}\\n\"\n",
        "            else:\n",
        "                latex_content += \"\\\\title{Literature Review}\\n\"\n",
        "            latex_content += \"\\\\author{Generated with AI Literature Review Tool}\\n\"\n",
        "            latex_content += \"\\\\date{\\\\today}\\n\"\n",
        "            latex_content += \"\\\\maketitle\\n\\n\"\n",
        "\n",
        "            # Add abstract\n",
        "            latex_content += \"\\\\begin{abstract}\\n\"\n",
        "            latex_content += \"This literature review synthesizes recent research papers on \" + \\\n",
        "                             (research_interest if research_interest else \"the selected topic\") + \\\n",
        "                             \". The review was generated using an AI-assisted tool that analyzed multiple academic papers.\\n\"\n",
        "            latex_content += \"\\\\end{abstract}\\n\\n\"\n",
        "\n",
        "            # Process the literature review text for LaTeX\n",
        "            # Convert markdown headers to LaTeX sections\n",
        "            review_latex = data\n",
        "            review_latex = re.sub(r'# (.*)', r'\\\\section{\\1}', review_latex)\n",
        "            review_latex = re.sub(r'## (.*)', r'\\\\subsection{\\1}', review_latex)\n",
        "            review_latex = re.sub(r'### (.*)', r'\\\\subsubsection{\\1}', review_latex)\n",
        "\n",
        "            # Convert markdown formatting\n",
        "            review_latex = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\\\textbf{\\1}', review_latex)\n",
        "            review_latex = re.sub(r'\\*(.*?)\\*', r'\\\\textit{\\1}', review_latex)\n",
        "\n",
        "            # Escape special characters\n",
        "            review_latex = review_latex.replace('_', '\\\\_').replace('%', '\\\\%').replace('&', '\\\\&')\n",
        "\n",
        "            # Add the processed review text\n",
        "            latex_content += review_latex + \"\\n\\n\"\n",
        "\n",
        "            # End document\n",
        "            latex_content += \"\\\\end{document}\"\n",
        "\n",
        "        else:\n",
        "            print(f\"Invalid data type or format for LaTeX export: {data_type}\")\n",
        "            return None\n",
        "\n",
        "        # Write to file\n",
        "        with open(output_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(latex_content)\n",
        "\n",
        "        print(f\"LaTeX content exported to {output_path}\")\n",
        "        return output_path\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error exporting to LaTeX: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example usage:\n",
        "# if comparison_df is not None:\n",
        "#     export_to_latex(comparison_df, \"paper_comparison_latex\", \"comparison\", research_interest)\n",
        "# if review_text:\n",
        "#     export_to_latex(review_text, \"literature_review_latex\", \"literature\", research_interest)"
      ],
      "metadata": {
        "id": "2P-k-R312oa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Paper Relationships"
      ],
      "metadata": {
        "id": "FZCG-KXW27yE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_paper_relationships(enhanced_papers):\n",
        "    \"\"\"\n",
        "    Create visualizations showing relationships between papers\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    enhanced_papers : list\n",
        "        List of papers with enhanced information\n",
        "    \"\"\"\n",
        "    if not enhanced_papers:\n",
        "        print(\"No papers available for visualization.\")\n",
        "        return\n",
        "\n",
        "    print(\"Creating visualizations of paper relationships...\")\n",
        "\n",
        "    # Extract themes from papers\n",
        "    themes = {}\n",
        "    for paper in enhanced_papers:\n",
        "        if 'key_themes' in paper and paper['key_themes']:\n",
        "            for theme in paper['key_themes']:\n",
        "                if theme in themes:\n",
        "                    themes[theme] += 1\n",
        "                else:\n",
        "                    themes[theme] = 1\n",
        "\n",
        "    # Create a dataframe with just titles and years for timeline\n",
        "    paper_years = []\n",
        "    for paper in enhanced_papers:\n",
        "        year = paper.get('year', 'N/A')\n",
        "        # Try to extract a year if it's not already in a standard format\n",
        "        if year != 'N/A':\n",
        "            # Try to extract a 4-digit year\n",
        "            match = re.search(r'20\\d\\d', str(year))\n",
        "            if match:\n",
        "                year = int(match.group(0))\n",
        "\n",
        "        paper_years.append({\n",
        "            'title': paper['title'][:50] + '...' if len(paper['title']) > 50 else paper['title'],\n",
        "            'year': year,\n",
        "            'relevance': paper['relevance']\n",
        "        })\n",
        "\n",
        "    # Create a timeline of papers if we have year data\n",
        "    has_years = any(isinstance(p['year'], (int, float)) for p in paper_years)\n",
        "    if has_years:\n",
        "        year_df = pd.DataFrame([p for p in paper_years if isinstance(p['year'], (int, float))])\n",
        "\n",
        "        if len(year_df) > 0:\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            plt.scatter(year_df['year'], year_df.index, s=year_df['relevance']*2, alpha=0.7)\n",
        "\n",
        "            for i, row in year_df.iterrows():\n",
        "                plt.text(row['year'], i, f\"  {row['title']}\", fontsize=9, va='center')\n",
        "\n",
        "            plt.yticks([])\n",
        "            plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "            plt.xlabel('Publication Year')\n",
        "            plt.title('Timeline of Relevant Papers')\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "    # Create a bar chart of themes if we have theme data\n",
        "    if themes:\n",
        "        theme_df = pd.DataFrame(list(themes.items()), columns=['Theme', 'Count'])\n",
        "        theme_df = theme_df.sort_values('Count', ascending=False).head(10)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.barh(theme_df['Theme'], theme_df['Count'], color='skyblue')\n",
        "        plt.xlabel('Number of Papers')\n",
        "        plt.title('Common Themes Across Papers')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Example usage:\n",
        "# if enhanced_papers:\n",
        "#     visualize_paper_relationships(enhanced_papers)"
      ],
      "metadata": {
        "id": "7OFq-6iP25aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Interactive Interface"
      ],
      "metadata": {
        "id": "Dl-5d6sm3Oh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def interactive_analysis():\n",
        "    \"\"\"\n",
        "    Create an interactive interface for paper analysis and literature review generation\n",
        "    \"\"\"\n",
        "    from ipywidgets import widgets\n",
        "    from IPython.display import display\n",
        "\n",
        "    # Create widgets for file input\n",
        "    file_input = widgets.Text(\n",
        "        value='arxiv_filtered_papers.csv',\n",
        "        description='CSV File:',\n",
        "        style={'description_width': 'initial'},\n",
        "        layout={'width': '50%'}\n",
        "    )\n",
        "\n",
        "    # Widget for research interest\n",
        "    interest_input = widgets.Text(\n",
        "        value='Applications of reinforcement learning in robotic control systems with sparse rewards',\n",
        "        description='Research Interest:',\n",
        "        style={'description_width': 'initial'},\n",
        "        layout={'width': '70%'}\n",
        "    )\n",
        "\n",
        "    # Relevance threshold\n",
        "    relevance_slider = widgets.IntSlider(\n",
        "        value=70,\n",
        "        min=0,\n",
        "        max=100,\n",
        "        step=5,\n",
        "        description='Min Relevance:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "\n",
        "    # Max papers\n",
        "    max_papers_slider = widgets.IntSlider(\n",
        "        value=8,\n",
        "        min=1,\n",
        "        max=20,\n",
        "        step=1,\n",
        "        description='Max Papers:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "\n",
        "    # Download full text option\n",
        "    download_papers = widgets.Checkbox(\n",
        "        value=True,\n",
        "        description='Download Full Paper Text',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "\n",
        "    # Checkbox for outputs\n",
        "    generate_review = widgets.Checkbox(\n",
        "        value=True,\n",
        "        description='Generate Literature Review',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "\n",
        "    generate_table = widgets.Checkbox(\n",
        "        value=True,\n",
        "        description='Generate Comparison Table',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "\n",
        "    export_csv = widgets.Checkbox(\n",
        "        value=True,\n",
        "        description='Export to CSV',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "\n",
        "    export_latex = widgets.Checkbox(\n",
        "        value=True,\n",
        "        description='Export to LaTeX (Overleaf)',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "\n",
        "    # Button to run analysis\n",
        "    run_button = widgets.Button(\n",
        "        description='Run Analysis',\n",
        "        button_style='success',\n",
        "        icon='play'\n",
        "    )\n",
        "\n",
        "    # Output widget for results\n",
        "    output = widgets.Output()\n",
        "\n",
        "    # Button click handler\n",
        "    def on_run_button_click(b):\n",
        "        with output:\n",
        "            output.clear_output()\n",
        "\n",
        "            # Load papers\n",
        "            papers_df = load_papers_from_csv(file_input.value)\n",
        "            if papers_df is None:\n",
        "                return\n",
        "\n",
        "            research_interest = interest_input.value\n",
        "            min_relevance = relevance_slider.value\n",
        "            max_papers = max_papers_slider.value\n",
        "\n",
        "            # Download full paper text if selected\n",
        "            if download_papers.value:\n",
        "                papers_df = enhance_papers_with_full_text(papers_df, max_papers=max_papers)\n",
        "\n",
        "            review_text = None\n",
        "            comparison_df = None\n",
        "            enhanced_papers = None\n",
        "\n",
        "            # Generate literature review if selected\n",
        "            if generate_review.value:\n",
        "                review_text, included_papers = generate_literature_review(\n",
        "                    papers_df, research_interest, min_relevance, max_papers\n",
        "                )\n",
        "                if review_text:\n",
        "                    display(Markdown(\"## Generated Literature Review\"))\n",
        "                    display(Markdown(review_text))\n",
        "\n",
        "            # Generate comparison table if selected\n",
        "            if generate_table.value:\n",
        "                comparison_df, enhanced_papers = create_comparison_table(\n",
        "                    papers_df, min_relevance, max_papers\n",
        "                )\n",
        "                if comparison_df is not None:\n",
        "                    display(Markdown(\"## Comparison Table\"))\n",
        "                    display(comparison_df)\n",
        "\n",
        "            # Visualize relationships\n",
        "            if enhanced_papers:\n",
        "                visualize_paper_relationships(enhanced_papers)\n",
        "\n",
        "            # Export to CSV if selected\n",
        "            if export_csv.value:\n",
        "                if comparison_df is not None:\n",
        "                    export_to_csv(comparison_df, \"paper_comparison_table\", \"comparison\")\n",
        "                if review_text:\n",
        "                    export_to_csv(review_text, \"literature_review\", \"literature\")\n",
        "\n",
        "            # Export to LaTeX if selected\n",
        "            if export_latex.value:\n",
        "                if comparison_df is not None:\n",
        "                    export_to_latex(comparison_df, \"paper_comparison_latex\", \"comparison\", research_interest)\n",
        "                if review_text:\n",
        "                    export_to_latex(review_text, \"literature_review_latex\", \"literature\", research_interest)\n",
        "\n",
        "    # Connect button to handler\n",
        "    run_button.on_click(on_run_button_click)\n",
        "\n",
        "    # Display widgets\n",
        "    display(widgets.HTML(\"<h2>Paper Analysis and Literature Review Generator</h2>\"))\n",
        "    display(widgets.HBox([file_input]))\n",
        "    display(widgets.HBox([interest_input]))\n",
        "    display(widgets.HBox([relevance_slider, max_papers_slider]))\n",
        "    display(widgets.HBox([download_papers]))\n",
        "    display(widgets.HBox([generate_review, generate_table, export_csv, export_latex]))\n",
        "    display(run_button)\n",
        "    display(output)\n",
        "\n",
        "# Uncomment to run the interactive interface\n",
        "# interactive_analysis()"
      ],
      "metadata": {
        "id": "gVw_z5743Oso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the interactive analysis"
      ],
      "metadata": {
        "id": "Aw7nTwrQ3ZZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment to run the interactive interface\n",
        "# interactive_analysis()"
      ],
      "metadata": {
        "id": "xCMW2vpq3_R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Example Usage"
      ],
      "metadata": {
        "id": "c9tV-MUt3wzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Simple Example Usage\n",
        "# ===========================\n",
        "\n",
        "def run_simple_example():\n",
        "    \"\"\"\n",
        "    Run a simple example of the entire pipeline\n",
        "    \"\"\"\n",
        "    # Load papers from CSV\n",
        "    papers_df = load_papers_from_csv('arxiv_filtered_papers.csv')\n",
        "    if papers_df is None:\n",
        "        print(\"Please make sure you have a file named 'arxiv_filtered_papers.csv' with the required columns.\")\n",
        "        return\n",
        "\n",
        "    # Define parameters\n",
        "    research_interest = \"Applications of reinforcement learning in robotic control systems with sparse rewards\"\n",
        "    min_relevance = 70\n",
        "    max_papers = 8\n",
        "\n",
        "    # Download full paper text\n",
        "    print(\"Downloading full paper text...\")\n",
        "    papers_df = enhance_papers_with_full_text(papers_df, max_papers=max_papers)\n",
        "\n",
        "    # Generate literature review\n",
        "    review_text, included_papers = generate_literature_review(\n",
        "        papers_df, research_interest, min_relevance, max_papers\n",
        "    )\n",
        "    if review_text:\n",
        "        display(Markdown(\"## Generated Literature Review\"))\n",
        "        display(Markdown(review_text))\n",
        "\n",
        "        # Export literature review\n",
        "        export_to_csv(review_text, \"literature_review\", \"literature\")\n",
        "        export_to_latex(review_text, \"literature_review_latex\", \"literature\", research_interest)\n",
        "\n",
        "    # Generate comparison table\n",
        "    comparison_df, enhanced_papers = create_comparison_table(\n",
        "        papers_df, min_relevance, max_papers\n",
        "    )\n",
        "    if comparison_df is not None:\n",
        "        display(Markdown(\"## Comparison Table\"))\n",
        "        display(comparison_df)\n",
        "\n",
        "        # Export comparison table\n",
        "        export_to_csv(comparison_df, \"paper_comparison_table\", \"comparison\")\n",
        "        export_to_latex(comparison_df, \"paper_comparison_latex\", \"comparison\", research_interest)\n",
        "\n",
        "    # Visualize relationships between papers\n",
        "    if enhanced_papers:\n",
        "        visualize_paper_relationships(enhanced_papers)\n",
        "\n",
        "    print(\"Example completed!\")\n",
        "\n",
        "# Uncomment to run the simple example\n",
        "run_simple_example()"
      ],
      "metadata": {
        "id": "oIa5UV693xyN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}